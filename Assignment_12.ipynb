{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmrCxd6tc+sZHr0oLiG1ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Deep-Learning/blob/main/Assignment_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.How does unsqueeze help us to solve certain broadcasting problems?\n",
        "\n",
        "Unsqueeze is a method to change the tensor dimensions, such that operations such as tensor multiplication can be possible. For example: If you want to multiply your tensor of size(4), with a tensor that has the size (4, N, N) then you'll get an error.\n",
        "\n",
        "Returns a new tensor with a dimension of size one inserted at the specified position. The returned tensor shares the same underlying data with this tensor. A dim value within the range [-input]\n",
        "\n"
      ],
      "metadata": {
        "id": "SAo6FYGd9O6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.How can we use indexing to do the same operation as unsqueeze?\n",
        "\n",
        "Unsqueeze is a method to change the tensor dimensions, such that operations such as tensor multiplication can be possible. For example: If you want to multiply your tensor of size(4), with a tensor that has the size (4, N, N) then you'll get an error."
      ],
      "metadata": {
        "id": "-0RySBHh-MU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.How do we show the actual contents of the memory used for a tensor?\n",
        "\n",
        "The commonly used way to store such data is in a single array that is laid out as a single, contiguous block within memory. More concretely, a 3x3x3 tensor would be stored simply as a single array of 27 values, one after the other."
      ],
      "metadata": {
        "id": "5YqkZBfiB4pA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.When adding a vector of size 3 to a matrix of size 3×3, are the elements of the vector added to each row or each column of the matrix? (Be sure to check your answer by running this code in a notebook.)"
      ],
      "metadata": {
        "id": "sio0Q4jWCEGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Do broadcasting and expand_as result in increased memory use? Why or why not?\n",
        "\n",
        "Variables of broadcast allow the developers of Spark to keep a secured read-only cached variable on different nodes. With the needed tasks, only shipping a copy merely. Without having to waste a lot of time and transfer of network input and output, they can be used in giving a node a large copy of the input dataset.\n",
        "\n",
        "Broadcast join is an important part of Spark SQL's execution engine. When used, it performs a join on two relations by first broadcasting the smaller one to all Spark executors, then evaluating the join criteria with each executor's partitions of the other relation."
      ],
      "metadata": {
        "id": "YsHxMqa2CLXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Implement matmul using Einstein summation.\n",
        "\n",
        "Sums the product of the elements of the input operands along dimensions specified using a notation based on the Einstein summation convention. The output is then computed by summing the product of the elements of the operands along the dimensions whose subscripts are not part of the output.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gc9q7lKOCWvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What does a repeated index letter represent on the lefthand side of einsum?\n",
        "\n",
        "It describes traditional matrix multiplication and is equivalent to np. matmul(a,b) . Repeated subscript labels in one operand take the diagonal. For example, np. einsum('ii', a) is equivalent to np."
      ],
      "metadata": {
        "id": "4AdyjuzSCm-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are the three rules of Einstein summation notation? Why?\n",
        "\n",
        "The “rules” of summation convention are: Each index can appear at most twice in any term. Repeated indices are implicitly summed over. Each term must contain identical non-repeated indices."
      ],
      "metadata": {
        "id": "ci4HwuVgCyhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What are the forward pass and backward pass of a neural network?\n",
        "\n",
        "A loss function is calculated from the output values. And then \"backward pass\" refers to process of counting changes in weights (de facto learning), using gradient descent algorithm (or similar). Computation is made from last layer, backward to the first layer. Backward and forward pass makes together one \"iteration\"."
      ],
      "metadata": {
        "id": "FOax9mUDC77y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Why do we need to store some of the activations calculated for intermediate layers in the forward pass?\n",
        "\n",
        "Activation functions are a critical part of the design of a neural network. The choice of activation function in the hidden layer will control how well the network model learns the training dataset. The choice of activation function in the output layer will define the type of predictions the model can make."
      ],
      "metadata": {
        "id": "BbJYKhlrDDqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is the downside of having activations with a standard deviation too far away from 1?\n",
        "\n",
        "The standard deviation from the minimum feasible value should be zero. If you are not approximately equal to at least two figures in your data set, the standard deviation must be higher than 0 – positive. Standard deviation cannot be negative in any conditions."
      ],
      "metadata": {
        "id": "VWnufvY_DPTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.How can weight initialization help avoid this problem?\n",
        "\n",
        "Weight initialization is an important design choice when developing deep learning neural network models. ... Weight initialization is used to define the initial values for the parameters in neural network models prior to training the models on a dataset.\n",
        "\n",
        "A network with improper weight initialization can make the entire learning process tedious and time-consuming. Therefore, to achieve better optimization, faster convergence, and feasible learning process weight initialization is very crucial."
      ],
      "metadata": {
        "id": "bKfvOmfQD1ax"
      }
    }
  ]
}