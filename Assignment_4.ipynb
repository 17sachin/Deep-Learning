{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo9trH3VqZZzB0pTUYv4GS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Deep-Learning/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
        "\n",
        "TensorFlow provides a collection of workflows to develop and train models using Python or JavaScript, and to easily deploy in the cloud, on-prem, in the browser, or on-device no matter what language you use. The tf. data API enables you to build complex input pipelines from simple, reusable pieces.\n",
        "\n",
        "Features of TensorFlow\n",
        "Open-source Library. It is an open-source library that allows rapid and easier calculations in machine learning. \n",
        "Easy to run. \n",
        "\n",
        "Fast Debugging. \n",
        "\n",
        "Effective. \n",
        "\n",
        "Scalable. \n",
        "\n",
        "Easy Experimentation.\n",
        "\n",
        "Abstraction. \n",
        "\n",
        "Flexibility."
      ],
      "metadata": {
        "id": "oT82OJn52cku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
        "\n",
        "Sure, it could but it probably won't. Keep in mind that NumPy is the foundation for other libraries. Pandas data objects sit on top of NumPy arrays. TensorFlow has become the gold standard in the applied space though.\n",
        "\n",
        "An array is a grid of values that contains raw data and we use it to locate and interpret elements in the raw data.The difference between a NumPy array and a tensor is that the tensors are backed by the accelerator memory like GPU and they are immutable, unlike NumPy arrays."
      ],
      "metadata": {
        "id": "LcrxQl7o3Ffq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
      ],
      "metadata": {
        "id": "4vr_7UCs3Zws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
        "\n",
        "There are four main tensor type you can create:\n",
        "Variable.\n",
        "\n",
        "constant.\n",
        "\n",
        "placeholder.\n",
        "\n",
        "SparseTensor."
      ],
      "metadata": {
        "id": "w7CYgxk43kpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.A custom loss function can be defined by writing a function or by subclassing\n",
        "the keras.losses.Loss class. When would you use each option?\n",
        "\n",
        "A custom loss function can be created by defining a function that takes the true values and predicted values as required parameters. The function should return an array of losses. The function can then be passed at the compile stage.\n",
        "\n",
        "The mean squared error loss function can be used in Keras by specifying 'mse' or 'mean_squared_error' as the loss function when compiling the model. It is recommended that the output layer has one node for the target variable and the linear activation function is used."
      ],
      "metadata": {
        "id": "DFg3q97p3zvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
        "\n",
        "As mentioned in Keras docu. import keras.backend as K def mean_pred(y_true, y_pred): return K.mean(y_pred) model. \n",
        "Or you can implement it in a hacky way as mentioned in Keras GH issue. For that you need to use callbacks argument of model."
      ],
      "metadata": {
        "id": "fHsW6jmf7Q_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.When should you create a custom layer versus a custom model?\n",
        "\n",
        "If you are building a new model architecture using existing keras/tf layers then build a custom model. If you are implementing your own custom tensor operations with in a layer, then build a custom layer"
      ],
      "metadata": {
        "id": "f-g22F5S7ci0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are some use cases that require writing your own custom training loop?\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "\n",
        "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "\n",
        "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
        "\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the training dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# Reserve 10,000 samples for validation.\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "Cqg-LML_7lGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QAYI6r24785-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
        "\n",
        "Tensorflow 2 comes up with a tight integration of Keras and an intuitive high-level API tf. keras to build neural networks and other ML models. You get the user-friendliness of Keras and can also be benefited from access to all low-level classes of TensorFlow."
      ],
      "metadata": {
        "id": "Ga0jbMmK8HMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
        "\n",
        "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability.\n",
        "\n",
        "You can use tf.function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use SavedModel.\n",
        "\n",
        "This guide will help you conceptualize how tf.function works under the hood, so you can use it effectively."
      ],
      "metadata": {
        "id": "QaOUMPu_8OuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
        "\n",
        "Keras is a neural network Application Programming Interface (API) for Python that is tightly integrated with TensorFlow, which is used to build machine learning models. Keras' models offer a simple, user-friendly way to define a neural network, which will then be built for you by TensorFlow.\n",
        "\n",
        "A dynamic model may also yield additional economic information of interest (e.g. a measure of persistence in your dependent variable, which also enables you to distinguish between the short-run impact effects and the long-run effects of your continuous variables)"
      ],
      "metadata": {
        "id": "mJrSyqdx8cHV"
      }
    }
  ]
}