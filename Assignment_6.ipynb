{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4w1iTlo2riFJghQAmHm4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Deep-Learning/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What are the advantages of a CNN over a fully connected DNN for image classification?\n",
        "\n",
        "The reason why Convolutional Neural Networks (CNNs) do so much better than classic neural networks on images and videos is that the convolutional layers take advantage of inherent properties of images. Simple feedforward neural networks don't see any order in their inputs."
      ],
      "metadata": {
        "id": "ygA4FCmZVEfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
        "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
        "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
        "\n",
        "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
        "RAM will this network require when making a prediction for a single instance? What about when\n",
        "training on a mini-batch of 50 images?"
      ],
      "metadata": {
        "id": "OHl36jcNVOUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?\n",
        "\n",
        "Reduce the mini-batch size. Reduce dimensionality using a larger stride in one or more layers. Remove one or more layers"
      ],
      "metadata": {
        "id": "gIq3qXFZVUVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?\n",
        "\n",
        "Max-pooling helps in extracting low-level features like edges, points, etc. While Avg-pooling goes for smooth features. If time constraint is not a problem, then one can skip the pooling layer and use a convolutional layer to do the same."
      ],
      "metadata": {
        "id": "rjAbXg8UVbF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.When would you want to add a local response normalization layer?\n",
        "\n",
        "Local Response Normalization (LRN) was first introduced in AlexNet architecture where the activation function used was ReLU as opposed to the more common tanh and sigmoid at that time. Apart from the reason mentioned above, the reason for using LRN was to encourage lateral inhibition"
      ],
      "metadata": {
        "id": "YYGEHAe4Vhts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
        "\n",
        "The main innovation introduced by AlexNet compared to the LeNet-5 was its sheer size. AlexNet main elements are the same: a sequence of convolutional and pooling layers followed by a couple of fully-connected layers"
      ],
      "metadata": {
        "id": "zRq_S7zYVmt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?\n",
        "\n",
        "The fully convolutional network first uses a CNN to extract image features, then transforms the number of channels into the number of classes via a 1×1 convolutional layer, and finally transforms the height and width of the feature maps to those of the input image via the transposed convolution."
      ],
      "metadata": {
        "id": "_-ZpuRn4Vsrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is the main technical difficulty of semantic segmentation?\n",
        "\n",
        "Semantic segmentation gives fine inference by predicting labels for every pixel in the input image. Each pixel is labelled according to the object class within which it is enclosed. Furthering this evolution, instance segmentation gives different labels for separate instances of objects belonging to the same class"
      ],
      "metadata": {
        "id": "FOgXEJa1VyJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l76QpJAKV5CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W8LmgNpLWCa8"
      }
    }
  ]
}