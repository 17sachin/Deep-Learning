{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOb4Xi+calxzdP7DyHU0z85",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Deep-Learning/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is the function of a summation junction of a neuron? What is threshold activation function?\n",
        "\n",
        "This process is called summation and occurs at the axon hillock, Additionally, one neuron often has inputs from many presynaptic neurons—some excitatory and some inhibitory—so IPSPs can cancel out EPSPs and vice versa.\n",
        "\n",
        "A threshold transfer function is sometimes used to quantify the output of a neuron in the output layer. ... All possible connections between neurons are allowed. Since loops are present in this type of network, it becomes a non-linear dynamic system which changes continuously until it reaches a state of equilibrium\n",
        "\n"
      ],
      "metadata": {
        "id": "e9oAdU5BWKnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is a step function? What is the difference of step function with threshold function?\n",
        "\n",
        "Mathematically speaking, a step function is a function whose graph looks like a series of steps because it consists of a series of horizontal line segments with jumps in-between. ... A step function has a constant value on given intervals, but the constant is different for each interval.\n",
        "\n",
        "A threshold transfer function is sometimes used to quantify the output of a neuron in the output layer. Feed-forward networks include Perceptron (linear and non-linear) and Radial Basis Function networks."
      ],
      "metadata": {
        "id": "mlS7eBEGWmO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Explain the McCulloch–Pitts model of neuron.\n",
        "\n",
        "The McCulloch–Pitt neural network is considered to be the first neural network. McCulloch–Pitt neuron allows binary activation (1 ON or 0 OFF), i.e., it either fires with an activation 1 or does not fire with an activation of 0. If w > 0, then the connected path is said to be excitatory else it is known as inhibitory."
      ],
      "metadata": {
        "id": "w1Wc9lbvW3rU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Explain the ADALINE network model.\n",
        "\n",
        "ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network. The network uses memistors. ... It is based on the McCulloch–Pitts neuron. It consists of a weight, a bias and a summation function."
      ],
      "metadata": {
        "id": "7nSnafn8XKVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is the constraint of a simple perceptron? Why it may fail with a real-world data set?\n",
        "\n",
        "Perceptron networks have several limitations. First, the output values of a perceptron can take on only one of two values (0 or 1) because of the hard-limit transfer function. Second, perceptrons can only classify linearly separable sets of vectors.\n",
        "\n"
      ],
      "metadata": {
        "id": "dJIKcqXyXSg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is linearly inseparable problem? What is the role of the hidden layer?\n",
        "\n",
        "A set of input vectors (or a training set) will be said to be linearly non-separable if no hyperplane exists such that each vector lies on the pre-assigned side of the hyperplane.\n",
        "\n",
        "The role of the Hidden Layers is to identify features from the input data and use these to correlate between a given input and the correct output.\n",
        "\n"
      ],
      "metadata": {
        "id": "URBFv4XvXrar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Explain XOR problem in case of a simple perceptron.\n",
        "\n",
        "XOR is linear un-division operation, which cannot be treated by single-layer perceptron. With the analysis, several solutions are proposed in the paper to solve the problems of XOR. Single-layer perceptron can be improved by multi-layer perceptron, functional perceptron or quadratic function."
      ],
      "metadata": {
        "id": "nw83E3EeX8EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Design a multi-layer perceptron to implement A XOR B.\n",
        "\n",
        "Implementation of Perceptron Algorithm for XOR Logic Gate with 2-bit Binary Input.\n",
        "0\t0\t0\n",
        "0\t1\t1\n",
        "1\t0\t1\n",
        "1\t1\t0"
      ],
      "metadata": {
        "id": "BUuJQWRvYHYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Explain the single-layer feed forward architecture of ANN.\n",
        "\n",
        "In this type of network, we have only two layers input layer and output layer but the input layer does not count because no computation is performed in this layer. The output layer is formed when different weights are applied on input nodes and the cumulative effect per node is taken."
      ],
      "metadata": {
        "id": "IaFCLU8DZLLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Explain the competitive network architecture of ANN.\n",
        "\n",
        "An Artificial Neural Network (ANN) is an information processing paradigm that is inspired by the brain. ANNs, like people, learn by examples. An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process."
      ],
      "metadata": {
        "id": "f5oCzmR3ZRKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Consider a multi-layer feed forward neural network. Enumerate and explain steps in the backpropagation algorithm used to train the network.\n",
        "\n",
        "Below are the steps involved in Backpropagation: Step – 1: Forward Propagation. Step – 2: Backward Propagation. Step – 3: Putting all the values together and calculating the updated weight value."
      ],
      "metadata": {
        "id": "vh6XG8aLZYfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What are the advantages and disadvantages of neural networks?\n",
        "\n",
        "Neural Networks have the ability to learn by themselves and produce the output that is not limited to the input provided to them. The input is stored in its own networks instead of a database, hence the loss of data does not affect its working.\n",
        "\n"
      ],
      "metadata": {
        "id": "nKPqkq72Zg7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.Write short notes on any two of the following:\n",
        "\n",
        "1.Biological neuron:\n",
        "Biological neurons, consisting of a cell body, axons, dendrites and synapses, are able to process and transmit neural activation.\n",
        "\n",
        "2.ReLU function:\n",
        "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. ... The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.\n",
        "\n",
        "3.Single-layer feed forward ANN:\n",
        "In this type of network, we have only two layers input layer and output layer but the input layer does not count because no computation is performed in this layer. The output layer is formed when different weights are applied on input nodes and the cumulative effect per node is taken.\n",
        "\n",
        "4.Gradient descent:\n",
        "Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression).\n",
        "\n",
        "5.Recurrent networks:\n",
        "A recurrent network combines the feedback and the feedforward connections of neural networks (see Figure 2.8). In other words, it is simply a neural network with loops connecting the output responses to the input layer. Thus, the output responses of the network function as additional input variables\n"
      ],
      "metadata": {
        "id": "pQN0CiBKZteF"
      }
    }
  ]
}