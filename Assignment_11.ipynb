{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa8jGe+IngYD3MxKJWHo2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Deep-Learning/blob/main/Assignment_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the “hidden size” of a layer?\n",
        "\n",
        "Hidden size is number of features of the hidden state for RNN. So if you increase hidden size then you compute bigger feature as hidden state output. However, num_layers is just multiple RNN units which contain hidden states with given hidden size."
      ],
      "metadata": {
        "id": "rWJ7zNoPWfMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does the t method do in PyTorch?\n",
        "\n",
        "torch. t (input) → Tensor. Expects input to be <= 2-D tensor and transposes dimensions 0 and 1. 0-D and 1-D tensors are returned as is. When input is a 2-D tensor this is equivalent to transpose(input, 0, 1) "
      ],
      "metadata": {
        "id": "NYp3M0NMWoya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is matrix multiplication written in plain Python very slow?\n",
        "\n",
        "The basic problem is that you're recursing down to a leaf size of 1 with your strassen implementaiton. Strassen's algorithm has a better Big O complexity, but constants do matter in reality, which means in reality you're better off with a standard n^3 matrix multiplication for smaller problem sizes."
      ],
      "metadata": {
        "id": "UjJF8lfkWuon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Jupyter Notebook, how do you measure the time taken for a single cell to execute?\n",
        "\n",
        "Measure execution time with Jupyter Notebook: %timeit , %%timeit. In Jupyter Notebook (IPython), you can use the magic commands %timeit and %%timeit to measure the execution time of your code"
      ],
      "metadata": {
        "id": "bwEVy_uJW5i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is elementwise arithmetic?\n",
        "\n",
        "It is a binary operation that takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands,"
      ],
      "metadata": {
        "id": "gwMnVtFuXAv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a rank-0 tensor? How do you convert it to a plain Python data type?\n",
        "\n"
      ],
      "metadata": {
        "id": "07JAxJTYXIyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the broadcasting rules?\n",
        "\n",
        "If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side. Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
        "\n"
      ],
      "metadata": {
        "id": "vpS-u_daXNwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is expand_as? Show an example of how it can be used to match the results of\n",
        "broadcasting.\n",
        "\n"
      ],
      "metadata": {
        "id": "T85M4WNmXYf8"
      }
    }
  ]
}